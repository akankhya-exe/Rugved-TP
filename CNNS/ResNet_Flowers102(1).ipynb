{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQ7wvnbDGnf9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(image_size=(128, 128)):\n",
        "  (ds_train, ds_validation), ds_info = tfds.load(\n",
        "      'oxford_flowers102',\n",
        "      split=['train', 'validation'],\n",
        "      shuffle_files=True,\n",
        "      as_supervised=True,\n",
        "      with_info=True,\n",
        "  )\n",
        "\n",
        "  num_classes = ds_info.features['label'].num_classes\n",
        "\n",
        "  def preprocess(image, label):\n",
        "    image = tf.image.resize(image, image_size)\n",
        "    label = tf.one_hot(label, depth=num_classes)\n",
        "    return image, label\n",
        "\n",
        "  ds_train = ds_train.map(preprocess).cache().shuffle(ds_info.splits['train'].num_examples).batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "  ds_validation = ds_validation.map(preprocess).cache().batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  return ds_train, ds_validation, num_classes, ds_info"
      ],
      "metadata": {
        "id": "0F78ihBqHReZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "train_dataset, validation_dataset, num_classes, ds_info = load_dataset(IMG_SIZE)\n",
        "\n",
        "class_names=ds_info.features['label'].names"
      ],
      "metadata": {
        "id": "ifMW5RWgHR5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_dataset.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        label_index = tf.argmax(labels[i])\n",
        "        plt.title(class_names[label_index])\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r2djK1snHTKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import RandomFlip, RandomRotation\n",
        "\n",
        "def data_augmenter():\n",
        "  data_augmentation = tf.keras.Sequential()\n",
        "  data_augmentation.add(RandomFlip(\"horizontal\"))\n",
        "  data_augmentation.add(RandomRotation(0.2))\n",
        "\n",
        "  return data_augmentation"
      ],
      "metadata": {
        "id": "oXbJcNhaHVsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = data_augmenter()\n",
        "\n",
        "for images, labels in train_dataset.take(1):\n",
        "    first_image = images[0]\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.suptitle(\"Augmentating one image\")\n",
        "\n",
        "    ax = plt.subplot(3, 3, 1)\n",
        "    plt.imshow(first_image.numpy().astype(\"uint8\"))\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    for i in range(8):\n",
        "        ax = plt.subplot(3, 3, i + 2)\n",
        "        augmented_image = data_augmentation(tf.expand_dims(first_image, 0), training=True)\n",
        "        plt.imshow(augmented_image[0].numpy().astype(\"uint8\"))\n",
        "        plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3413g2thHWHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_input_resnet\n",
        "train_dataset_resnet = train_dataset.map(lambda image, label: (preprocess_input_resnet(image), label))"
      ],
      "metadata": {
        "id": "i5cBs8DuHXPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "def flower_model(image_shape=IMG_SIZE, data_augmentation=data_augmenter()):\n",
        "  input_shape = image_shape + (3,)\n",
        "\n",
        "  base_model = ResNet50(input_shape=input_shape,\n",
        "                       include_top=False,\n",
        "                       weights='imagenet',\n",
        "                      name='resnet50')\n",
        "\n",
        "  base_model.trainable = False\n",
        "\n",
        "  inputs = Input(shape=input_shape)\n",
        "\n",
        "  x = data_augmentation(inputs)\n",
        "\n",
        "  x = preprocess_input_resnet(x)\n",
        "\n",
        "  x = base_model(x, training=False)\n",
        "\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "  x = Dropout(0.2)(x)\n",
        "\n",
        "  outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "  model = Model(inputs, outputs)\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "GWVg058iHfcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = flower_model(IMG_SIZE, data_augmenter())"
      ],
      "metadata": {
        "id": "-ohcjEitJWAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "                     loss='categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_dataset,\n",
        "                                  epochs=10,\n",
        "                                  validation_data=validation_dataset)"
      ],
      "metadata": {
        "id": "LXrhKzlAKcrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T2pQZjmjLHjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(validation_dataset)\n",
        "print(f\"Validation Loss: {loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "yaO5X6GlLLiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = model.get_layer('resnet50')\n",
        "base_model.trainable = True\n",
        "\n",
        "# ResNet has 175 layers\n",
        "fine_tune_at = 165 # Finetuning 25 layers\n",
        "\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-6)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "fine_tune_epochs = 30\n",
        "total_epochs = 10 + fine_tune_epochs\n",
        "\n",
        "history_fine_tune = model.fit(train_dataset,\n",
        "                              epochs=total_epochs,\n",
        "                              initial_epoch=history.epoch[-1],\n",
        "                              validation_data=validation_dataset)\n"
      ],
      "metadata": {
        "id": "QczxW25SLP0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(validation_dataset)\n",
        "print(f\"Validation Loss: {loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "jzpf-4woQK3o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}